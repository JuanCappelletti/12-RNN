{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Networks)\n",
    "Articulos recomendado: \n",
    "- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- http://blog.echen.me/2017/05/30/exploring-lstms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que tienen de nuevo respecto a MLP y CNN?\n",
    "- MLP y CNN solo aceptan un vector de entrada de tamaño fijo y devuelve un vector de salida de tamaño fijo\n",
    "- RNN trabjan con secuencias tanto a la entrada como a la salida\n",
    "- No tienen por que estrictamente tener una secuencia ni a la entrada ni a la salidad. De hecho hasta podrían no tener nada a la \"entrada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<src img=\"rnn_types.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aclaraciones: \n",
    "- Cada cuadrado NO es una neurona si no una capa que puede contener N neuronas\n",
    "- Cada flecha representa la interconexión entre dos capas. Los pesos forman una matriz de la N1xN2 donde N1 y N2 son la cantidad de neuronas en cada capa respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos\n",
    "\n",
    "<img src=\"imgs/rnn_types.jpeg\">\n",
    "\n",
    "- **One to One**: CNN, MLP\n",
    "- **One to many**: [Image captioning](https://www.youtube.com/watch?v=xKt21ucdBY0)\n",
    "- **Many to one**: Sentiment Analisys, Detectar voz de hombre vs voz de mujer\n",
    "- **Many to Many** [(sequence to sequence)](https://youtu.be/dkHdEAJnV_w): [Traducción](https://github.com/jganzabal/aind2-nlp-capstone/blob/master/machine_translation.ipynb) Dimensión de entrada differente a la de salida.\n",
    "- **Many to Many Sincronizado**: Etiquetado de tramas de video, POS (Part of Speech) cada palabra se clasifica en verbo, articulo, etc, speech2text, text2speech, NER (Named Entity Recognition). Dimensión de entrada igual a dimensión de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de lenguaje Generativos:\n",
    "- Predecir la proxima palabra en funcion de las anteriores\n",
    "- Predecir el proximo caracter en función de los anteriores\n",
    "\n",
    "**Resultado**: Probabilidad dada la secuencia de caracteres o de palabras\n",
    "\n",
    "**Aplicaciones de los modelos de lenguaje** (Mas allá de la posibilidad de generar texto):\n",
    "- OCR\n",
    "- Speach2Text\n",
    "- Detección de autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.\"\n",
    "- Es una secuencia de ejecución mas que una clasificación\n",
    "- Las RNN son Turing completo en principio [Turing Complete](https://en.wikipedia.org/wiki/Turing_completeness), [RNN Turing complete](http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalles de la arquitectura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidad de Elman o RNN unit\n",
    "\n",
    "**Nota importante**: Cada unidad no es una neurona sino que una capa\n",
    "\n",
    "<img src=\"imgs/RNN_vs_FNN.png\">\n",
    "\n",
    "¿Cual es el tamaño de $W_h$?\n",
    "\n",
    "Todo se conecta con todo -> Si hay M hidden units tenemos $M^2$ $W_h$s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En ecuaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN\n",
    "\n",
    "$h_t = f(W_x^T X_t + b_h)$\n",
    "\n",
    "$y_t = softmax(W_o^T h_t + b_o)$\n",
    "\n",
    "$f$ usualmente RELU, sigmoidea, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t = f(W_h^T h_{t-1} + W_x^T X_t + b_h)$\n",
    "\n",
    "$y_t = softmax(W_o^T h_t + b_o)$\n",
    "\n",
    "$f$ es tanh usualmente pero puede ser RELU, sigmoid, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_neurons = 2\n",
    "time_steps = 1000 # T\n",
    "n_features = 3 # D\n",
    "input_shape = (time_steps, n_features)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(rnn_neurons, input_shape = input_shape))\n",
    "model.add(Dense(3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que es time_steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desplegando (Unfolding) la RNN\n",
    "#### BPTT (Back-Propagation Through Time)\n",
    "- Secuencia de longitud 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/unfold_RNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- Es como una FNN con 5 hidden layers pero con pesos compartidos (Shared weights): $W_h, W_o, W_x$\n",
    "- Donde habiamos visto pesos compartidos?\n",
    "- Se puede pensar como si h fuera la entrada y X es una señal de control en cada paso\n",
    "\n",
    "Preguntas:\n",
    "- Son todas las Y importantes? En que casos?\n",
    "- Que diferencia hay entre estado interno (internal state) de la RNN y los pesos?\n",
    "- Cada cuanto se resetea el estado interno? Y los pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detalles de la entrada $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrada en Vanilla Networks:\n",
    "\n",
    "NxD, donde N es la cantidad de muestras y D es la cantidad de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.3]\n",
      " [0.2 0.1]\n",
      " [0.7 0.3]]\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo N = 3, D = 2\n",
    "Ex_1 = np.array([[0.5, 0.3], [0.2, 0.1], [0.7, 0.3]])\n",
    "print(Ex_1)\n",
    "print(Ex_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrada en RNNs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secuencias de longitud fija\n",
    "\n",
    "NxTxD, donde T es la longitud de la secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5  0.3 ]\n",
      "  [0.2  0.1 ]\n",
      "  [0.7  0.3 ]]\n",
      "\n",
      " [[0.54 0.1 ]\n",
      "  [0.23 0.3 ]\n",
      "  [0.9  0.1 ]]\n",
      "\n",
      " [[0.5  0.3 ]\n",
      "  [0.2  0.1 ]\n",
      "  [0.7  0.3 ]]\n",
      "\n",
      " [[0.54 0.1 ]\n",
      "  [0.23 0.3 ]\n",
      "  [0.9  0.1 ]]]\n",
      "(4, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo N = 4, T = 3, D=2\n",
    "Ex_2 = np.array([[[0.5, 0.3], [0.2, 0.1], [0.7, 0.3]], [[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]], [[0.5, 0.3], [0.2, 0.1], [0.7, 0.3]], [[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]]])\n",
    "print(Ex_2)\n",
    "print(Ex_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secuencias de longitud variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([[0.5, 0.3], [0.7, 0.3]])\n",
      " list([[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]]) list([[0.7, 0.3]])\n",
      " list([[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]])]\n",
      "(4,)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "Ex_3 = np.array([[[0.5, 0.3], [0.7, 0.3]], [[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]], [[0.7, 0.3]], [[0.54, 0.1], [0.23, 0.3], [0.9, 0.1]]])\n",
    "print(Ex_3)\n",
    "print(Ex_3.shape)\n",
    "print(np.array(Ex_3[0]).shape)\n",
    "print(np.array(Ex_3[1]).shape)\n",
    "print(np.array(Ex_3[2]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tensorflow es posible, en keras se suele hacer padding\n",
    "\n",
    "¿Que pasa cuando tenemos longitudes distintas? Analizar el unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desventajas de padding\n",
    "- Podría haber una secuencia de longitud mayor en el test set. Que hacemos con eso?\n",
    "- Es probable que los casos de secuencia largas sean poco probables por lo que realizaremos multiplicaciones de matrices innecesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumiendo:\n",
    "## RNN vs Vanilla Network\n",
    "- Menor cantidad de parametros para resolver lo mismo\n",
    "- En principio una FFN podria resolver con la misma precisión un problema resuelto por una RNN, pero es demasiado complejo encontrar la solución\n",
    "- La estructura de la RNN simplifica la tarea de encontrar una solución de manera eficiente\n",
    "- Ya sabemos que el problema tiene naturaleza recurrente (necesitamos memoria)\n",
    "- FNN tienen que tener tamaño fijo en contraste con las RNNs\n",
    "\n",
    "## Las RNN pueden resolver problemas muy diferentes desde el punto de vista del tipo de procesamiento sobre la secuencia\n",
    "- Secuencia temporal modelada con \"longitud infinita\": Valor de acciones - Modelos tipo AR(N)\n",
    "- Secuencias finitas \"independientes\" unas de otras: Sentiment analisys (Longitud variable), paridad (Longitud fija)\n",
    "- Modelos de lenguaje: Por caracter o por palabra\n",
    "- Seq2Seq: Traducción, chatbots, Image captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](BiLSTM-Image-classif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
