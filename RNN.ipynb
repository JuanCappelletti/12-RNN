{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones\n",
    "- Detectar voz de hombre vs voz de mujer: Sequence to label\n",
    "- Brain Computer Interface (BCI): Controlar una silla de ruedas. Sequence to sequence.\n",
    "- Predecir la proxima palabra en funcion de las anteriores (parecido a autoencoders): No supervisado. No es Markov por que toma no solo las anteriores. Se estima lo mismo que en HMM pero sin la asumpción de que es Markov. Problema de Marov en el producto grande de muchas probabilidades pequeñas, no aparece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = ['h', 'e', 'l', 'l','o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_hot = {\n",
    "             'h':[1, 0, 0, 0],\n",
    "             'e':[0,1,0,0],\n",
    "             'l':[0,0,1,0],\n",
    "             'o':[0,0,0,1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1, 4), (4, 4))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = np.array([to_hot[c] for c in word[:-1]]).reshape(len(word)-1,-1,len(set(word)))\n",
    "labels_train = np.array([to_hot[c] for c in word[1:]]) #.reshape(len(word)-1,-1,len(set(word)))\n",
    "data_train.shape, labels_train.shape\n",
    "#(number_of_samples, window_size, number_of_dif_chars)\n",
    "#()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 0]]), array([0, 0, 0, 1]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[3], labels_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_45 (LSTM)               (None, 3)                 96        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 112\n",
      "Trainable params: 112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "# input_shape=(timesteps, data_dim)\n",
    "model.add(LSTM(3, input_shape=(1, 4)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130cfb6a0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, labels_train, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09072253,  0.77222037,  0.12523173,  0.01182537],\n",
       "       [ 0.01216853,  0.09912954,  0.77941167,  0.10929023],\n",
       "       [ 0.00313022,  0.01961189,  0.53796566,  0.43929225],\n",
       "       [ 0.00313022,  0.01961189,  0.53796566,  0.43929225]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_train[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model_MLP = Sequential()\n",
    "model_MLP.add(Dense(3, input_dim=4))\n",
    "model_MLP.add(Dense(4, activation='softmax'))\n",
    "model_MLP.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ed7dc18>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.fit(data_train.reshape(4,4), labels_train, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0189336 ,  0.84607023,  0.12648895,  0.00850716],\n",
       "       [ 0.00243876,  0.09905881,  0.84283036,  0.0556721 ],\n",
       "       [ 0.01423129,  0.02748223,  0.49583361,  0.46245283],\n",
       "       [ 0.01423129,  0.02748223,  0.49583361,  0.46245283]], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.predict(data_train[0:4].reshape(4,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
