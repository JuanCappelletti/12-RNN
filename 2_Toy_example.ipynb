{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import sys \n",
    "# sys.path.append(\"/Users/julianganzabal/facultad/lab-ml/mllab-tools\")\n",
    "from RNN_utils import encode_io_pairs, chars_to_one_hot, sample, window_transform_text\n",
    "from fnn_helper import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formas diferentes de entrenar una RNN con el mismo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprender los siguientes conceptos:\n",
    "- Diferencias entre MLP (con features igual a timesteps) y RNN\n",
    "- Stateful vs stateles en Keras\n",
    "- Mini-Batch traininig vs SGD training\n",
    "- Los pesos se actualizan en el backward mientras que el estado de la RNN cambia con cada timestep en el forward\n",
    "- Padding\n",
    "- Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de dataset (frase) y preformateo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elegimos una frase que tenga una letras repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=\"MACHINE LEARNING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres distintos:\n",
      "[' ', 'A', 'C', 'E', 'G', 'H', 'I', 'L', 'M', 'N', 'R']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print('Caracteres distintos:')\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=1\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'A': 1,\n",
       " 'C': 2,\n",
       " 'E': 3,\n",
       " 'G': 4,\n",
       " 'H': 5,\n",
       " 'I': 6,\n",
       " 'L': 7,\n",
       " 'M': 8,\n",
       " 'N': 9,\n",
       " 'R': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: 'A',\n",
       " 2: 'C',\n",
       " 3: 'E',\n",
       " 4: 'G',\n",
       " 5: 'H',\n",
       " 6: 'I',\n",
       " 7: 'L',\n",
       " 8: 'M',\n",
       " 9: 'N',\n",
       " 10: 'R'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto a One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 0 0 0 0 0 1 0 0]\n",
      "  [0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 1 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0 0 0 0]\n",
      "  [0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 1 0 0 0 0 0 0]]]\n",
      "(1, 16, 11)\n"
     ]
    }
   ],
   "source": [
    "one_hot_text = chars_to_one_hot(text, chars, chars_to_indices, window_size)*1\n",
    "print(one_hot_text)\n",
    "print(one_hot_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot a caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices_to_chars[np.argmax(one_hot_text[0][0])])\n",
    "print(indices_to_chars[np.argmax(one_hot_text[0][1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: T = 1\n",
    "En este ejemplo usaremos una RNN pero como una simple vanilla network (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparo entrada/salida:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_transform_text(text, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "step_size = 1\n",
    "# encode_io_pairs llama a window_transform_text y despues codifica en one-hot\n",
    "X, y = encode_io_pairs(text, chars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X:', X.shape, 'y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N: ', X.shape[0])\n",
    "print('T: ', X.shape[1])\n",
    "print('D: ', X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xi in X:\n",
    "    print(xi*1, indices_to_chars[np.argmax(xi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yi in y:\n",
    "    print(yi*1, indices_to_chars[np.argmax(yi)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que la salida es el siguiente caracter al de la entrada\n",
    "\n",
    "Esto es equivalente a un MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(10, input_shape=(window_size,len(chars))))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entreno el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model.fit(X,y, epochs=500, batch_size=1, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que no llega al 100%? Que es lo que no puede predecir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción usando argmax (Greedy Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_predict = text[0]\n",
    "to_predict = chars_to_one_hot(char_to_predict, chars, chars_to_indices, window_size)*1\n",
    "print(char_to_predict, '=', to_predict)\n",
    "predicted = model.predict(to_predict)\n",
    "print(predicted)\n",
    "print(indices_to_chars[np.argmax(predicted)], np.max(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_to_predict = text[:]\n",
    "print(chars_to_predict)\n",
    "# Los paso a one hot\n",
    "to_predict = chars_to_one_hot(chars_to_predict, chars, chars_to_indices, window_size)*1\n",
    "print(to_predict)\n",
    "print(to_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengo que hacer reshape para darselo a la red\n",
    "to_predict_reshaped = to_predict.reshape(to_predict.shape[1],to_predict.shape[0],to_predict.shape[2])\n",
    "print(to_predict_reshaped)\n",
    "print(to_predict_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de transición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(to_predict_reshaped)\n",
    "print(predicted.shape)\n",
    "print('    ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "for i, row in enumerate(predicted):\n",
    "    print(indices_to_chars[np.argmax(to_predict[:,i])], (row*100).astype(int)/100, indices_to_chars[np.argmax(row)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que pasa con la A y la N cuando el texto es MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: T = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparo entrada/salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "x_2_t, y_2_t = window_transform_text(text, window_size, step_size)\n",
    "for i, te in enumerate(x_2_t):\n",
    "    print(te, '->' ,y_2_t[i])\n",
    "#print(x_2_t, y_2_t)\n",
    "X_2, y_2 = encode_io_pairs(text, chars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_2.shape, X_2*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_2*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(SimpleRNN(10, input_shape=(window_size,len(chars))))\n",
    "model_2.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entreno modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model_2.fit(X_2,y_2, epochs=500, batch_size=1, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de transición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_2.predict(X_2)\n",
    "print(predicted.shape)\n",
    "print('     ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "for i, row in enumerate(predicted):\n",
    "    print(indices_to_chars[np.argmax(X_2[i, :][0])]+indices_to_chars[np.argmax(X_2[i, :][1])], (row*100).astype(int)/100, indices_to_chars[np.argmax(row)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que NI todavía no se puede predecir debido a la ambiguedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como es de esperar la predicción mejora notablemente\n",
    "- La cantidad de parametros de la red no cambia respecto a la anterior\n",
    "- Que pasa si lo implemento con MLP con la cantidad de parámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 3: T = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparo entrada/salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "x_3_t, y_3_t = window_transform_text(text, window_size, step_size)\n",
    "for i, te in enumerate(x_3_t):\n",
    "    print(te, '->' ,y_3_t[i])\n",
    "#print(x_2_t, y_2_t)\n",
    "X_3, y_3 = encode_io_pairs(text, chars, window_size, step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(SimpleRNN(10, input_shape=(window_size,len(chars))))\n",
    "model_3.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entreno modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiar batch_size y verificar que converge de la misma manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model_3.fit(X_3,y_3, epochs=500, batch_size=4, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como funciona la RNN con un batch size mayor que 1?\n",
    "- En que momento se resetea el estado?\n",
    "- Que dimensión tendrá el vector de estados durante el entrenamiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de transición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_3.predict(X_3)\n",
    "print(predicted.shape)\n",
    "print('     ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "for i, row in enumerate(predicted):\n",
    "    print(indices_to_chars[np.argmax(X_3[i, :][0])]+\n",
    "          indices_to_chars[np.argmax(X_3[i, :][1])]+\n",
    "          indices_to_chars[np.argmax(X_3[i, :][2])], \n",
    "          (row*100).astype(int)/100, indices_to_chars[np.argmax(row)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las probabilidades son practicamente 1\n",
    "- La cantidad de parametros de la red no cambia respecto a la anterior\n",
    "- Que pasa si lo implemento con MLP con la cantidad de parámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefino Modelo con pesos aprendidos pero statefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "model_3s = Sequential()\n",
    "model_3s.add(SimpleRNN(10, batch_input_shape=(batch_size,1,len(chars)), stateful=True))\n",
    "model_3s.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_3s.summary()\n",
    "model_3s.set_weights(model_3.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=1\n",
    "model_3s.reset_states()\n",
    "input_char = text[0]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que con un solo caracter ingresado, no tiene suficiente data para predecir (Ningun caracter tiene alta probabilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[1]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la predicción no tiene por que ser correcta a esta altura debido a que el modelo nunca fue entrenado con la secuencia ingresada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[2]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que luego de la tercer predicción el modelo predice casi perfectamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[3]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar como suele bajar la probabilidad de la predicción debido a que el modelo no tiene por que predecir secuencias mayores a la longitud entrenada (Aunque en ciertas circunstancias podría generalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[4]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[5]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya a esta altura estoy tratando de predecir algo probablemente demasiado lejano y no lo puede predecir correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por eso, si quiero predecir una nueva secuencia de tres, tengo que resetear el estado y luego  mandar de a un caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3s.reset_states()\n",
    "input_char = text[3]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[4]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = text[5]\n",
    "print('char de entrada:',input_char)\n",
    "to_predict = chars_to_one_hot(input_char, chars, chars_to_indices, window_size)*1\n",
    "predicted = model_3s.predict(to_predict)\n",
    "print('   ', end='')\n",
    "for c in chars_to_indices.keys():\n",
    "    print(c, end='     ')\n",
    "print()\n",
    "print((predicted*100).astype(int)/100)\n",
    "print('char predicted:', indices_to_chars[np.argmax(predicted[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que aca tiene una predicción muy alta debido a que esta secuencia fue vista por el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión importante:  \n",
    "Si puede usar la statefull para predecir, pero hay que alimentar con el largo orignal de la secuencia para que la salida empiece a tener sentido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 4: Stateful RNN\n",
    "Entreno en modo stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_transform_text(text, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "model_4 = Sequential()\n",
    "model_4.add(SimpleRNN(10, batch_input_shape=(batch_size,1,len(chars)), stateful=True))\n",
    "model_4.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notar que X e y son los mismos que en el caso T = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observar: shuffle=False y stateful=True\n",
    "- Puedo usar otro batch size en este caso?\n",
    "- Por que suffle tiene que estar en false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "for i in range(300):\n",
    "    model_4.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "    model_4.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voy ingresando de a uno la frase original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con 0, 3, 4, 7 y 1\n",
    "starting = 1\n",
    "model_4.reset_states()\n",
    "for c in text[starting:]:\n",
    "    to_predict = chars_to_one_hot(c, chars, chars_to_indices, window_size)*1\n",
    "    predicted = model_4.predict(to_predict)\n",
    "    print(c, '->', indices_to_chars[np.argmax(predicted[0])], int(max(predicted[0])*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con starting en (text es MACHINE LEARNING):\n",
    "- 0 Predice todo correctamente\n",
    "- 6 Al arrancar en E puede ser tanto la de L**E**AR.. o la de CHIN**E** .. por lo que no tiene demasiada certeza\n",
    "- 4 La I da alta probabilidad para la N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realimentando salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting = 0\n",
    "model_4.reset_states()\n",
    "c = text[starting]\n",
    "for i in range(25):\n",
    "    to_predict = chars_to_one_hot(c, chars, chars_to_indices, window_size)*1\n",
    "    predicted = model_4.predict(to_predict)\n",
    "    pred_char = indices_to_chars[np.argmax(predicted[0])]\n",
    "    print(c, '->', pred_char, int(max(predicted[0])*100)/100)\n",
    "    c = pred_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 5: Padding\n",
    "\"The model will learn the zero values carry no information so indeed the sequences are not the same length in terms of content, but same length vectors is required to perform the computation in Keras.\" https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "Como entreno no-statefull pero que de resultados similares a la statefull?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_transform_text_padding_mode(text):\n",
    "    len_out = len(text)\n",
    "    \n",
    "    #output_start[-1] = text[:1]\n",
    "    #output_start[len_out-1:len_out-2] = text[0:1]\n",
    "    text = text\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len_out):\n",
    "        #X.append()\n",
    "        output_start = ['']*(len_out-1)\n",
    "        output_start[len_out-i-1:len_out] = text[0:i]\n",
    "        X.append(output_start)\n",
    "        y.append(text[i])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo entradas con padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5, y_5 = window_transform_text_padding_mode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "chars_to_indices[''] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_chars(X, y, chars_to_indices):\n",
    "    X_coded = []\n",
    "    y_coded = []\n",
    "    for i, xi in enumerate(X):\n",
    "        one_h_y = [0]*(len(chars_to_indices) - 1) # Menos 1 por el '' agregado\n",
    "        vect = []\n",
    "        for c in xi:\n",
    "            one_h = [0]*(len(chars_to_indices) - 1)\n",
    "            if c == '':\n",
    "                vect.append(one_h)\n",
    "            else:\n",
    "                one_h[chars_to_indices[c]] = 1\n",
    "                vect.append(one_h)\n",
    "        X_coded.append(vect)\n",
    "        one_h_y[chars_to_indices[y[i]]] = 1\n",
    "        y_coded.append(one_h_y)\n",
    "    return np.array(X_coded), np.array(y_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_coded, y_coded = code_chars(X_5, y_5, chars_to_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_coded.shape, y_coded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer entrada todos ceros\n",
    "#[['', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "X_coded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'M'],\n",
    "X_coded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entreno modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(SimpleRNN(10, input_shape=(X_coded.shape[1],X_coded.shape[2])))\n",
    "model_5.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model_5.fit(X_coded,y_coded, epochs=500, batch_size=1, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = X_coded\n",
    "predicted = model_5.predict(to_predict)\n",
    "for i, row in enumerate(predicted):\n",
    "    idx = np.argmax(row)\n",
    "    print(X_5[i], '->', indices_to_chars[idx], int(row[idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora redefino modelo como stateful y cargo los pesos del anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "model_5s = Sequential()\n",
    "model_5s.add(SimpleRNN(10, batch_input_shape=(batch_size,1,len(chars)), stateful=True))\n",
    "model_5s.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_5s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5s.set_weights(model_5.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donde esta el maximo si ingereso ceros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5s.reset_states()\n",
    "to_predict = np.zeros((1,1,y_coded.shape[1]))\n",
    "for i in range(20):\n",
    "    predicted = model_5s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(i+1, to_predict, '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5s.reset_states()\n",
    "to_predict = np.zeros((1,1,y_coded.shape[1]))\n",
    "for i in range(0):\n",
    "    predicted = model_5s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(i+1, to_predict, '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    to_predict = y_coded[i:i+1].reshape(1, 1, len(chars))\n",
    "    predicted = model_5s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(to_predict, '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realimento salida\n",
    "Pero no ingreso con one-hot sino con las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=1\n",
    "model_5s.reset_states()\n",
    "to_predict = np.zeros((1,1,y_coded.shape[1]))\n",
    "for i in range(2):\n",
    "    predicted = model_5s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(i+1, to_predict, '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)\n",
    "#print(predicted.shape)\n",
    "for i in range(16):\n",
    "    to_predict = predicted.reshape(1, 1, len(chars))\n",
    "    predicted = model_5s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print((to_predict*100).astype(int)/100, '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 6: Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Masking(mask_value=0., input_shape=(X_coded.shape[1],X_coded.shape[2])))\n",
    "model_6.add(SimpleRNN(10))\n",
    "model_6.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo entreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model_6.fit(X_coded,y_coded, epochs=1000, batch_size=1, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = X_coded\n",
    "predicted = model_6.predict(to_predict)\n",
    "for i, row in enumerate(predicted):\n",
    "    idx = np.argmax(row)\n",
    "    print(X_5[i], '->', indices_to_chars[idx], int(row[idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armo modelo stateful y cargo pesos de modelo anterior entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6s = Sequential()\n",
    "model_6s.add(Masking(mask_value=0., batch_input_shape=(batch_size,1,len(chars))))\n",
    "model_6s.add(SimpleRNN(10, batch_input_shape=(batch_size,1,len(chars)), stateful=True))\n",
    "model_6s.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_6s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6s.set_weights(model_6.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentar el reset_states y ver que pasa\n",
    "# Entrenar 2 de 500 epochs\n",
    "\n",
    "model_6s.reset_states()\n",
    "\n",
    "for i in range(16):\n",
    "    to_predict = y_coded[i:i+1].reshape(1, 1, len(chars))\n",
    "    predicted = model_6s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(str(to_predict)+' '+text[i], '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrancando del medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6s.reset_states()\n",
    "st = 8\n",
    "for i in range(5):\n",
    "    to_predict = y_coded[i+st:i+st+1].reshape(1, 1, len(chars))\n",
    "    predicted = model_6s.predict(to_predict)\n",
    "    idx = np.argmax(predicted[0])\n",
    "    print(str(to_predict)+' '+text[i+st], '->', indices_to_chars[idx], int(predicted[0][idx]*100)/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ventajas/Desventajas entre este método y stateful\n",
    "- Ventajas: Este metodo permite el entrenamiento de a batches de manera mas simple\n",
    "- Desventajas: Se la secuencia es muy larga el unfolding termina siendo demasiado largo y requiere mas memoria y procesamiento\n",
    "\n",
    "Nota: En stateful, dependiendo del problema, se puede entrenar con batch size mayor a uno pero hay que pensar bien el armado de las secuencias de entrenamiento.\n",
    "\n",
    "Un ejemplo podría ser: Tengo que generar frases cortas de longitud variable y quiero que aprenda un modelo de lenguage para generar una frase corta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 7: Return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres distintos:\n",
      "[' ', '#', '$', 'A', 'C', 'E', 'G', 'H', 'I', 'L', 'M', 'N', 'R']\n",
      "[[[0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "  [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "  [1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "  [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "  [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0 0 0 0 0 0 0]]]\n",
      "(1, 18, 13)\n"
     ]
    }
   ],
   "source": [
    "text=\"#MACHINE LEARNING$\"\n",
    "chars = sorted(set(text))\n",
    "print('Caracteres distintos:')\n",
    "print(chars)\n",
    "window_size=1\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))\n",
    "one_hot_text = chars_to_one_hot(text, chars, chars_to_indices, window_size)*1\n",
    "print(one_hot_text)\n",
    "print(one_hot_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = one_hot_text[:, :-1, :]\n",
    "y_train = one_hot_text[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 17, 13), (1, 17, 13))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_8 (SimpleRNN)     (None, 17, 10)            240       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 17, 13)            143       \n",
      "=================================================================\n",
      "Total params: 383\n",
      "Trainable params: 383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.models import Sequential\n",
    "model_7 = Sequential()\n",
    "model_7.add(LSTM(10, return_sequences=True, input_shape=(X_train.shape[1],len(chars))))\n",
    "model_7.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAEyCAYAAACLeQv5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzP8DNBHl2xBHXXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e810908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2428 - acc: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2419 - acc: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2410 - acc: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2401 - acc: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2392 - acc: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2383 - acc: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2374 - acc: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2365 - acc: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2356 - acc: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2347 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e923240>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_losses = PlotLosses(plot_interval=10, evaluate_interval=None)\n",
    "model_7.fit(X_train,y_train, epochs=500, batch_size=1, verbose=1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 13)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.predict(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  3,  4,  7,  8, 11,  5,  0,  9,  5,  3, 12, 11,  8, 11,  6,  2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '#',\n",
       " 2: '$',\n",
       " 3: 'A',\n",
       " 4: 'C',\n",
       " 5: 'E',\n",
       " 6: 'G',\n",
       " 7: 'H',\n",
       " 8: 'I',\n",
       " 9: 'L',\n",
       " 10: 'M',\n",
       " 11: 'N',\n",
       " 12: 'R'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder decoder\n",
    "https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis con CNN y LSTM\n",
    "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# return_sequence vs return_state\n",
    "https://www.quora.com/What-is-the-difference-between-states-and-outputs-in-LSTM\n",
    "\n",
    "https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated BPTT \n",
    "https://machinelearningmastery.com/truncated-backpropagation-through-time-in-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
