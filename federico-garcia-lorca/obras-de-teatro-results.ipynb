{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/Users/julianganzabal/facultad/lab-ml/mllab-tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNN_utils import get_deep_rnn, chars_to_one_hot, sample\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  (100, 69)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 200)          216000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 69)                13869     \n",
      "=================================================================\n",
      "Total params: 550,669\n",
      "Trainable params: 550,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=get_deep_rnn((100, 69), dense_units=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bodes_sangre_LSTM_deep\n",
    "# bodes_sangre_LSTM_deep_dropout_04\n",
    "model.load_weights('bodes_sangre_LSTM_deep_dropout_04.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_and_get_dicts(text, train_fraction=0.6):\n",
    "    number_of_chars = len(text)\n",
    "    validation_index = int(number_of_chars*train_fraction)\n",
    "    text_train = text[:validation_index]\n",
    "    text_validation = text[validation_index:]\n",
    "    chars_train = set(text_train)\n",
    "    chars_test = set(text_validation)\n",
    "    chars_set = chars_train.intersection(chars_test)\n",
    "    chars = sorted(list(chars_set))\n",
    "    chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "    indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character\n",
    "    return text_train, text_validation, chars_to_indices, indices_to_chars, chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('bodas_de_sangre.txt').read()\n",
    "text_train, text_validation, chars_to_indices, indices_to_chars, chars = split_data_and_get_dicts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOZO 1: (Entrando) ¡Tienes que beber con nosotros!\n",
      "\n",
      "NOVIO: Estoy esperando a la novia.\n",
      "\n",
      "MOZO 2: ¡Ya \n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "initial_char = 16\n",
    "initial_text = text_validation[initial_char:window_size+initial_char]\n",
    "print(initial_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 69)\n"
     ]
    }
   ],
   "source": [
    "X_test = chars_to_one_hot(initial_text, chars, chars_to_indices, window_size)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.67503987e-04   1.47814702e-04   6.57919809e-05   2.55768944e-04\n",
      "    4.72745478e-06   2.37566437e-05   2.42656661e-05   2.75124034e-06\n",
      "    3.70589163e-07   4.40745964e-08   3.66885047e-06   1.64531309e-06\n",
      "    6.16733596e-05   7.41606073e-06   1.38893965e-05   8.09141711e-05\n",
      "    5.61719680e-05   4.66866550e-05   1.43318912e-05   3.72988325e-06\n",
      "    7.39485222e-06   2.96074631e-05   2.25158919e-06   1.05969375e-03\n",
      "    2.02943091e-04   3.09547031e-05   3.36788726e-05   1.23046950e-04\n",
      "    3.96312571e-05   1.16490854e-04   6.03278386e-05   4.03931081e-05\n",
      "    1.16660331e-05   1.97234822e-05   2.18112382e-05   1.14414220e-08\n",
      "    3.21773416e-03   1.22510139e-02   5.05333766e-02   1.11963920e-01\n",
      "    7.49744996e-02   1.27892541e-02   1.42459823e-02   2.28233449e-02\n",
      "    8.94579384e-03   8.82903347e-04   1.80775244e-02   6.82415813e-02\n",
      "    1.20949820e-01   1.26354326e-03   6.70492575e-02   4.00202051e-02\n",
      "    8.58152471e-03   8.35077390e-02   9.80713144e-02   1.13407243e-02\n",
      "    1.37485445e-01   2.20518807e-04   2.24742107e-02   2.44643219e-04\n",
      "    3.40348022e-04   8.25364259e-04   1.34834166e-09   3.73011571e-03\n",
      "    5.78770996e-04   1.17530697e-03   1.10614703e-04   5.82166285e-05\n",
      "    1.42767880e-04]]\n",
      "56\n",
      "v\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict(X_test)\n",
    "print(probs)\n",
    "index = np.argmax(probs)\n",
    "print(index)\n",
    "print(indices_to_chars[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestrar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5   0.25  0.15  0.1 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatura = 1\n",
    "sample([0.5, 0.25, 0.15, 0.10], temperatura, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOZO 1: (Entrando) ¡Tienes que beber con nosotros!\n",
      "\n",
      "NOVIO: Estoy esperando a la novia.\n",
      "\n",
      "MOZO 2: ¡Ya \n",
      "v\n",
      "v\n",
      "t\n",
      "d\n",
      "v\n",
      "d\n",
      "d\n",
      "e\n",
      "v\n",
      "v\n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "initial_char = 16\n",
    "initial_text = text_validation[initial_char:window_size+initial_char]\n",
    "print(initial_text)\n",
    "X_test = chars_to_one_hot(initial_text, chars, chars_to_indices, window_size)\n",
    "probs = model.predict(X_test)\n",
    "for i in range(10):\n",
    "    my_sample = sample(probs[0], 0.5)\n",
    "    print(indices_to_chars[my_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovia. (Se va.)\n",
      "\n",
      "MOZO 1: (Entrando) ¡Tienes que beber con nosotros!\n",
      "\n",
      "NOVIO: Estoy esperando a la novi\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "initial_char = 0\n",
    "initial_text = text_validation[initial_char:window_size+initial_char]\n",
    "print(initial_text)\n",
    "X_test = chars_to_one_hot(initial_text, chars, chars_to_indices, window_size)\n",
    "probs = model.predict(X_test)\n",
    "for i in range(10):\n",
    "    my_sample = sample(probs[0], 0.5)\n",
    "    print(indices_to_chars[my_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOZO 1: (Entrando) ¡Tienes que beber con nosotros!\n",
      "\n",
      "NOVIO: Estoy esperando a la novia.\n",
      "\n",
      "MOZO 2: ¡Ya \n",
      "---------------------------------------------------\n",
      "\n",
      "MOZO 1: (Entrando) ¡Tienes que beber con nosotros!\n",
      "\n",
      "NOVIO: Estoy esperando a la novia.\n",
      "\n",
      "MOZO 2: ¡Ya verdes!\n",
      "\n",
      "VECINA: Sí, pero de pendo a verdado no está me puede y el novio de lo mijo.\n",
      "\n",
      "MADRE: ¿Y qué?\n",
      "\n",
      "NOVIO: Me vanta esto y buena con la casa.\n",
      "\n",
      "MADRE: ¡Vamos a la viña?\n",
      "\n",
      "CRIADA: (Al novio) ¡Qué para \n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "initial_char = 16\n",
    "initial_text = text_validation[initial_char:window_size+initial_char]\n",
    "\n",
    "N = 200\n",
    "X_text_str = initial_text\n",
    "print(initial_text)\n",
    "print('---------------------------------------------------')\n",
    "print()\n",
    "for i in range(N):\n",
    "    X_test = chars_to_one_hot(X_text_str[i:], chars, chars_to_indices, window_size)\n",
    "    probs = model.predict(X_test)\n",
    "    my_sample=sample(probs[0], 0.5)\n",
    "    new_char = indices_to_chars[my_sample]\n",
    "    X_text_str = X_text_str + new_char\n",
    "print(X_text_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mantiene estructuta de obra de teatro\n",
    "- MADRE: ¿Y qué? -> Abre y cierra signo de pregunta \n",
    "- CRIADA: (Al novio) -> Abre y cierra parentesis\n",
    "- el novio, la viña, la casa -> Articulo mas sustantivo con género"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
