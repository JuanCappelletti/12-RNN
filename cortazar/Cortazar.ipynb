{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1409.2329.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1512.05287.pdf\n",
    "\n",
    "http://www.cs.toronto.edu/~graves/preprint.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leo cuentos completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 735543 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('cortazar.txt').read()\n",
    "print('our original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimo primeros 1000 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "era un vampiro. No le tenían miedo pero le dejaban paso\n",
      "cuando él salía de su tumba a la hora precisa de medianoche\n",
      "y entraba al antiguo castillo en procura de su alimento\n",
      "favorito.\n",
      "El rostro de Duggu Van no era agradable. La mucha\n",
      "sangre bebida desde su muerte aparente —en el 1060, a\n",
      "manos de un niño, nuevo David armado de una hondapuñal—\n",
      "había infiltrado en su opaca piel la coloración\n",
      "blanda de las maderas que han estado mucho tiempo debajo\n",
      "del agua. Lo único vivo, en esa cara, eran los ojos.\n",
      "Ojos fijos en la figura de Lady Vanda, dormida como un\n",
      "bebé en el lecho que no conocía más que su liviano cuerpo.\n",
      "Duggu Van caminaba sin hacer ruido. La mezcla de\n",
      "vida y muerte que informaba su corazón se resolvía en\n",
      "cualidades inhumanas. Vestido de azul oscuro, acompa-\n",
      "ñado siempre por un silencioso séquito de perfumes rancios,\n",
      "el vampiro paseaba por las galerías del castillo bus-\n",
      "20\n",
      "cando vivos\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quito numeracíon de páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20\\n', '21\\n', '22\\n', '23\\n', '25\\n', '26\\n', '27\\n', '28\\n', '29\\n', '30\\n', '31\\n', '32\\n', '33\\n', '34\\n', '69\\n', '70\\n', '71\\n', '72\\n', '73\\n', '74\\n', '76\\n', '77\\n', '78\\n', '79\\n', '80\\n', '81\\n', '82\\n', '83\\n', '84\\n', '85\\n', '87\\n', '88\\n', '89\\n', '90\\n', '91\\n', '92\\n', '93\\n', '94\\n', '95\\n', '96\\n', '97\\n', '99\\n', '100\\n', '101\\n', '102\\n', '103\\n', '104\\n', '105\\n', '106\\n', '107\\n', '109\\n', '110\\n', '111\\n', '112\\n', '113\\n', '114\\n', '115\\n', '116\\n', '117\\n', '118\\n', '119\\n', '120\\n', '121\\n', '122\\n', '124\\n', '125\\n', '126\\n', '127\\n', '128\\n', '129\\n', '130\\n', '131\\n', '132\\n', '133\\n', '134\\n', '135\\n', '136\\n', '137\\n', '138\\n', '139\\n', '140\\n', '142\\n', '143\\n', '144\\n', '145\\n', '146\\n', '147\\n', '148\\n', '149\\n', '150\\n', '151\\n', '152\\n', '153\\n', '154\\n', '155\\n', '156\\n', '157\\n', '158\\n', '160\\n', '161\\n', '162\\n', '163\\n', '164\\n', '165\\n', '166\\n', '167\\n', '168\\n', '169\\n', '170\\n', '177\\n', '178\\n', '180\\n', '181\\n', '182\\n', '183\\n', '184\\n', '186\\n', '187\\n', '188\\n', '190\\n', '191\\n', '192\\n', '193\\n', '194\\n', '195\\n', '196\\n', '197\\n', '198\\n', '199\\n', '200\\n', '201\\n', '202\\n', '203\\n', '204\\n', '206\\n', '207\\n', '208\\n', '209\\n', '210\\n', '211\\n', '212\\n', '213\\n', '214\\n', '216\\n', '217\\n', '218\\n', '219\\n', '220\\n', '221\\n', '222\\n', '223\\n', '225\\n', '226\\n', '227\\n', '228\\n', '229\\n', '230\\n', '231\\n', '245\\n', '246\\n', '247\\n', '248\\n', '249\\n', '250\\n', '251\\n', '252\\n', '253\\n', '254\\n', '255\\n', '256\\n', '257\\n', '258\\n', '259\\n', '261\\n', '262\\n', '263\\n', '264\\n', '265\\n', '266\\n', '267\\n', '268\\n', '269\\n', '271\\n', '272\\n', '273\\n', '274\\n', '275\\n', '276\\n', '277\\n', '278\\n', '280\\n', '281\\n', '282\\n', '283\\n', '284\\n', '286\\n', '287\\n', '289\\n', '290\\n', '291\\n', '292\\n', '293\\n', '294\\n', '295\\n', '296\\n', '297\\n', '298\\n', '300\\n', '301\\n', '302\\n', '303\\n', '304\\n', '305\\n', '307\\n', '308\\n', '309\\n', '310\\n', '311\\n', '312\\n', '313\\n', '314\\n', '315\\n', '317\\n', '318\\n', '319\\n', '320\\n', '321\\n', '322\\n', '323\\n', '324\\n', '325\\n', '326\\n', '327\\n', '328\\n', '329\\n', '342\\n', '343\\n', '344\\n', '345\\n', '346\\n', '347\\n', '348\\n', '349\\n', '350\\n', '351\\n', '352\\n', '353\\n', '354\\n', '355\\n', '356\\n', '357\\n', '358\\n', '359\\n', '360\\n', '361\\n', '362\\n', '363\\n', '373\\n', '374\\n', '375\\n', '376\\n', '377\\n', '378\\n', '379\\n', '380\\n', '381\\n', '382\\n', '383\\n', '384\\n', '385\\n', '386\\n', '387\\n', '388\\n', '389\\n', '391\\n', '392\\n', '393\\n', '394\\n', '395\\n', '396\\n', '398\\n', '399\\n', '400\\n', '401\\n', '402\\n', '403\\n', '404\\n', '405\\n', '406\\n', '407\\n', '408\\n', '409\\n', '410\\n', '411\\n', '412\\n', '413\\n', '414\\n', '415\\n', '416\\n', '417\\n', '418\\n', '419\\n', '420\\n', '421\\n', '422\\n', '423\\n', '424\\n', '425\\n', '426\\n', '427\\n', '428\\n', '429\\n', '430\\n', '431\\n', '432\\n', '433\\n', '434\\n', '435\\n', '436\\n', '437\\n', '438\\n', '439\\n', '440\\n', '441\\n', '442\\n', '443\\n', '444\\n', '445\\n', '446\\n', '447\\n', '448\\n', '449\\n', '450\\n', '451\\n', '452\\n', '453\\n', '454\\n', '455\\n', '456\\n', '457\\n', '458\\n', '459\\n', '460\\n', '461\\n', '462\\n', '463\\n', '483\\n', '484\\n', '485\\n', '486\\n', '487\\n', '488\\n', '489\\n', '490\\n', '491\\n', '492\\n', '493\\n', '494\\n', '497\\n', '498\\n', '499\\n', '500\\n', '501\\n', '502\\n', '503\\n', '504\\n', '505\\n', '506\\n', '507\\n', '508\\n', '509\\n', '510\\n', '511\\n', '512\\n', '513\\n', '514\\n', '517\\n', '518\\n', '519\\n', '520\\n', '521\\n', '522\\n', '523\\n', '524\\n', '527\\n', '528\\n', '529\\n', '530\\n', '531\\n', '532\\n', '533\\n', '534\\n', '535\\n', '536\\n', '537\\n', '538\\n', '539\\n', '540\\n', '541\\n', '542\\n', '543\\n', '544\\n', '545\\n', '546\\n', '547\\n', '548\\n']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "numbers=[]\n",
    "while i<len(text):\n",
    "    number = ''\n",
    "    while text[i] in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        number=number+text[i]\n",
    "        i += 1\n",
    "    if len(number)>0:\n",
    "        if text[i-len(number)-1]=='\\n' and text[i]=='\\n':\n",
    "            numbers.append(number+'\\n')\n",
    "    i += 1\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quito caracteres no frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_cleaned = text\n",
    "for num in numbers:\n",
    "    text_cleaned = text_cleaned.replace(num,'')\n",
    "text_cleaned = text_cleaned.replace('–','-').replace('[','(').replace(']',')'). \\\n",
    "                replace(\"'\",'\"').replace(\"—\",'-').replace(\"”\", '\"').replace('“','\"').replace('‘','\"').\\\n",
    "                replace(\"«\",'\"').replace(\"»\",'\"').replace('‚',',').replace('*','').replace('ô','o').replace('´',' ').\\\n",
    "                replace('°',' ').replace('º',' ').replace('/',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimo primeros 1000 caracteres limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "era un vampiro. No le tenían miedo pero le dejaban paso\n",
      "cuando él salía de su tumba a la hora precisa de medianoche\n",
      "y entraba al antiguo castillo en procura de su alimento\n",
      "favorito.\n",
      "El rostro de Duggu Van no era agradable. La mucha\n",
      "sangre bebida desde su muerte aparente -en el 1060, a\n",
      "manos de un niño, nuevo David armado de una hondapuñal-\n",
      "había infiltrado en su opaca piel la coloración\n",
      "blanda de las maderas que han estado mucho tiempo debajo\n",
      "del agua. Lo único vivo, en esa cara, eran los ojos.\n",
      "Ojos fijos en la figura de Lady Vanda, dormida como un\n",
      "bebé en el lecho que no conocía más que su liviano cuerpo.\n",
      "Duggu Van caminaba sin hacer ruido. La mezcla de\n",
      "vida y muerte que informaba su corazón se resolvía en\n",
      "cualidades inhumanas. Vestido de azul oscuro, acompa-\n",
      "ñado siempre por un silencioso séquito de perfumes rancios,\n",
      "el vampiro paseaba por las galerías del castillo bus-\n",
      "cando vivos de\n"
     ]
    }
   ],
   "source": [
    "print(text_cleaned[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino train y validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXOLOTL\n",
      "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
      "Iba a verlos al acuario del Jardín des Plantes y me quedaba\n",
      "horas mirándolos, observando su inmovilidad, sus\n",
      "oscuros movimientos. Ahora soy un axolotl.\n",
      "El azar me llevó hasta ellos una mañana de primavera\n",
      "en que París abría su cola de pavo real después de la\n",
      "lenta invernada. Bajé por el bulevar de Port Royal, tomé\n",
      "St. Marcel y L’Hopita\n"
     ]
    }
   ],
   "source": [
    "validation_index = text_cleaned.find('AXOLOTL')\n",
    "print(text_cleaned[validation_index:validation_index+400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383053\n",
      "351034\n"
     ]
    }
   ],
   "source": [
    "text_train = text_cleaned[:validation_index]\n",
    "text_validation = text_cleaned[validation_index:]\n",
    "print(len(text_train))\n",
    "print(len(text_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino cantidad de clases (caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 734087 total number of characters\n",
      "this corpus has 88 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars_train = set(text_train)\n",
    "chars_test = set(text_validation)\n",
    "chars_set = chars_train.intersection(chars_test)\n",
    "chars = sorted(list(chars_set))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text_cleaned)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 118621),\n",
       " ('a', 75540),\n",
       " ('e', 73036),\n",
       " ('o', 52626),\n",
       " ('s', 40959),\n",
       " ('n', 38909),\n",
       " ('r', 37276),\n",
       " ('l', 32903),\n",
       " ('i', 28156),\n",
       " ('d', 26654),\n",
       " ('u', 23652),\n",
       " ('t', 22723),\n",
       " ('c', 21882),\n",
       " ('m', 17126),\n",
       " ('p', 14254),\n",
       " ('\\n', 13734),\n",
       " ('b', 9820),\n",
       " (',', 9195),\n",
       " ('y', 6775),\n",
       " ('q', 6764),\n",
       " ('h', 6279),\n",
       " ('.', 6240),\n",
       " ('v', 5883),\n",
       " ('g', 5654),\n",
       " ('í', 4888),\n",
       " ('f', 3266),\n",
       " ('j', 2955),\n",
       " ('ó', 2779),\n",
       " ('á', 2689),\n",
       " ('z', 2577),\n",
       " ('é', 2405),\n",
       " ('E', 1247),\n",
       " ('-', 1195),\n",
       " ('L', 1190),\n",
       " ('A', 1076),\n",
       " ('ñ', 934),\n",
       " ('P', 787),\n",
       " ('C', 758),\n",
       " ('M', 751),\n",
       " ('N', 737),\n",
       " ('S', 734),\n",
       " ('D', 618),\n",
       " ('ú', 599),\n",
       " ('\"', 522),\n",
       " ('T', 496),\n",
       " ('x', 490),\n",
       " ('R', 485),\n",
       " ('J', 454),\n",
       " ('Y', 424),\n",
       " (';', 384),\n",
       " ('B', 351),\n",
       " ('I', 329),\n",
       " ('O', 289),\n",
       " ('H', 287),\n",
       " ('U', 284),\n",
       " ('(', 278),\n",
       " (')', 277),\n",
       " (':', 263),\n",
       " ('V', 197),\n",
       " ('?', 173),\n",
       " ('¿', 170),\n",
       " ('Q', 128),\n",
       " ('F', 125),\n",
       " ('G', 107),\n",
       " ('k', 102),\n",
       " ('1', 81),\n",
       " ('2', 58),\n",
       " ('3', 47),\n",
       " ('4', 41),\n",
       " ('É', 40),\n",
       " ('w', 37),\n",
       " ('¡', 32),\n",
       " ('!', 32),\n",
       " ('5', 32),\n",
       " ('8', 22),\n",
       " ('6', 21),\n",
       " ('0', 18),\n",
       " ('9', 18),\n",
       " ('ü', 18),\n",
       " ('Ó', 16),\n",
       " ('’', 16),\n",
       " ('Á', 16),\n",
       " ('Í', 15),\n",
       " ('7', 15),\n",
       " ('K', 12),\n",
       " ('W', 9),\n",
       " ('Z', 8),\n",
       " ('Ú', 7),\n",
       " ('X', 4),\n",
       " ('è', 3),\n",
       " ('î', 3),\n",
       " ('â', 2),\n",
       " ('&', 2),\n",
       " ('Ñ', 1)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(text_cleaned).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para dar formato a la entrada/salida de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_transform_text(text, window_size, step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    # This is the number of iterations taking into acount the step_size and the window_size\n",
    "    N = int((len(text)-window_size)/step_size)\n",
    "    # Get inputs and outputs\n",
    "    for k in range(N):\n",
    "        i = k*step_size\n",
    "        inputs.append(text[i:i+window_size])\n",
    "        outputs.append(text[i+window_size])\n",
    "        \n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 3\n",
    "inputs, outputs = window_transform_text(text_train,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "output = \n",
      "\n",
      "--------------\n",
      "input = GIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "er\n",
      "output = a\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[0])\n",
    "print('output = ' + outputs[0])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[1])\n",
    "print('output = ' + outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " ';': 19,\n",
       " '?': 20,\n",
       " 'A': 21,\n",
       " 'B': 22,\n",
       " 'C': 23,\n",
       " 'D': 24,\n",
       " 'E': 25,\n",
       " 'F': 26,\n",
       " 'G': 27,\n",
       " 'H': 28,\n",
       " 'I': 29,\n",
       " 'J': 30,\n",
       " 'K': 31,\n",
       " 'L': 32,\n",
       " 'M': 33,\n",
       " 'N': 34,\n",
       " 'O': 35,\n",
       " 'P': 36,\n",
       " 'Q': 37,\n",
       " 'R': 38,\n",
       " 'S': 39,\n",
       " 'T': 40,\n",
       " 'U': 41,\n",
       " 'V': 42,\n",
       " 'W': 43,\n",
       " 'Y': 44,\n",
       " 'Z': 45,\n",
       " 'a': 46,\n",
       " 'b': 47,\n",
       " 'c': 48,\n",
       " 'd': 49,\n",
       " 'e': 50,\n",
       " 'f': 51,\n",
       " 'g': 52,\n",
       " 'h': 53,\n",
       " 'i': 54,\n",
       " 'j': 55,\n",
       " 'k': 56,\n",
       " 'l': 57,\n",
       " 'm': 58,\n",
       " 'n': 59,\n",
       " 'o': 60,\n",
       " 'p': 61,\n",
       " 'q': 62,\n",
       " 'r': 63,\n",
       " 's': 64,\n",
       " 't': 65,\n",
       " 'u': 66,\n",
       " 'v': 67,\n",
       " 'w': 68,\n",
       " 'x': 69,\n",
       " 'y': 70,\n",
       " 'z': 71,\n",
       " '¡': 72,\n",
       " '¿': 73,\n",
       " 'Á': 74,\n",
       " 'É': 75,\n",
       " 'Í': 76,\n",
       " 'Ó': 77,\n",
       " 'Ú': 78,\n",
       " 'á': 79,\n",
       " 'è': 80,\n",
       " 'é': 81,\n",
       " 'í': 82,\n",
       " 'ñ': 83,\n",
       " 'ó': 84,\n",
       " 'ú': 85,\n",
       " 'ü': 86,\n",
       " '’': 87}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars_to_indices)\n",
    "chars_to_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text,chars, window_size,step_size):\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char not in chars_to_indices:\n",
    "                char = ' '\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        out_char = outputs[i]\n",
    "        if out_char not in chars_to_indices:\n",
    "            out_char = ' '\n",
    "        y[i, chars_to_indices[out_char]] = 1\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use your function\n",
    "window_size = 100\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = encode_io_pairs(text_train, chars, window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validation, y_validation = encode_io_pairs(text_validation, chars, window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382953, 100, 88) (382953, 88)\n",
      "(350934, 100, 88) (350934, 88)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simple_rnn():\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    # First layer\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars))))\n",
    "    # Second layer\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    # lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0\n",
    "    # optimizer = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_deeper_no_rnn_dropout():\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)), return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_deeper_rnn():\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)), return_sequences=True, \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)),  \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_deeper_rnn()\n",
    "model.load_weights('best_RNN_dropout_50_epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 382953 samples, validate on 350934 samples\n",
      "Epoch 1/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4848Epoch 00000: val_loss improved from inf to 1.56427, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 840s - loss: 1.4848 - val_loss: 1.5643\n",
      "Epoch 2/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4818Epoch 00001: val_loss did not improve\n",
      "382953/382953 [==============================] - 767s - loss: 1.4817 - val_loss: 1.5675\n",
      "Epoch 3/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4811Epoch 00002: val_loss did not improve\n",
      "382953/382953 [==============================] - 757s - loss: 1.4811 - val_loss: 1.5651\n",
      "Epoch 4/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4811Epoch 00003: val_loss improved from 1.56427 to 1.56381, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 726s - loss: 1.4811 - val_loss: 1.5638\n",
      "Epoch 5/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4794Epoch 00004: val_loss did not improve\n",
      "382953/382953 [==============================] - 723s - loss: 1.4794 - val_loss: 1.5640\n",
      "Epoch 6/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4793Epoch 00005: val_loss improved from 1.56381 to 1.56216, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 715s - loss: 1.4794 - val_loss: 1.5622\n",
      "Epoch 7/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4814Epoch 00006: val_loss did not improve\n",
      "382953/382953 [==============================] - 681s - loss: 1.4815 - val_loss: 1.5627\n",
      "Epoch 8/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4793Epoch 00007: val_loss did not improve\n",
      "382953/382953 [==============================] - 657s - loss: 1.4793 - val_loss: 1.5649\n",
      "Epoch 9/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4799Epoch 00008: val_loss improved from 1.56216 to 1.55636, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 659s - loss: 1.4799 - val_loss: 1.5564\n",
      "Epoch 10/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4789Epoch 00009: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4790 - val_loss: 1.5637\n",
      "Epoch 11/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4771Epoch 00010: val_loss improved from 1.55636 to 1.55598, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 661s - loss: 1.4771 - val_loss: 1.5560\n",
      "Epoch 12/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4782Epoch 00011: val_loss did not improve\n",
      "382953/382953 [==============================] - 660s - loss: 1.4782 - val_loss: 1.5603\n",
      "Epoch 13/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4776Epoch 00012: val_loss did not improve\n",
      "382953/382953 [==============================] - 657s - loss: 1.4776 - val_loss: 1.5646\n",
      "Epoch 14/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4771Epoch 00013: val_loss improved from 1.55598 to 1.55542, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 661s - loss: 1.4770 - val_loss: 1.5554\n",
      "Epoch 15/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4747Epoch 00014: val_loss did not improve\n",
      "382953/382953 [==============================] - 657s - loss: 1.4747 - val_loss: 1.5577\n",
      "Epoch 16/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4755Epoch 00015: val_loss improved from 1.55542 to 1.55485, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 658s - loss: 1.4756 - val_loss: 1.5549\n",
      "Epoch 17/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4763Epoch 00016: val_loss improved from 1.55485 to 1.55156, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 658s - loss: 1.4762 - val_loss: 1.5516\n",
      "Epoch 18/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4735Epoch 00017: val_loss did not improve\n",
      "382953/382953 [==============================] - 662s - loss: 1.4735 - val_loss: 1.5535\n",
      "Epoch 19/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4768Epoch 00018: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4768 - val_loss: 1.5549\n",
      "Epoch 20/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4752Epoch 00019: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4752 - val_loss: 1.5546\n",
      "Epoch 21/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4728Epoch 00020: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4727 - val_loss: 1.5526\n",
      "Epoch 22/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4709Epoch 00021: val_loss did not improve\n",
      "382953/382953 [==============================] - 657s - loss: 1.4709 - val_loss: 1.5542\n",
      "Epoch 23/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4742Epoch 00022: val_loss improved from 1.55156 to 1.54551, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 659s - loss: 1.4742 - val_loss: 1.5455\n",
      "Epoch 24/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4694Epoch 00023: val_loss did not improve\n",
      "382953/382953 [==============================] - 662s - loss: 1.4694 - val_loss: 1.5510\n",
      "Epoch 25/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4676Epoch 00024: val_loss did not improve\n",
      "382953/382953 [==============================] - 661s - loss: 1.4677 - val_loss: 1.5522\n",
      "Epoch 26/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4699Epoch 00025: val_loss did not improve\n",
      "382953/382953 [==============================] - 660s - loss: 1.4699 - val_loss: 1.5536\n",
      "Epoch 27/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4680Epoch 00026: val_loss did not improve\n",
      "382953/382953 [==============================] - 660s - loss: 1.4679 - val_loss: 1.5519\n",
      "Epoch 28/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4738Epoch 00027: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4738 - val_loss: 1.5501\n",
      "Epoch 29/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4652Epoch 00028: val_loss did not improve\n",
      "382953/382953 [==============================] - 662s - loss: 1.4652 - val_loss: 1.5464\n",
      "Epoch 30/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4651Epoch 00029: val_loss did not improve\n",
      "382953/382953 [==============================] - 665s - loss: 1.4651 - val_loss: 1.5493\n",
      "Epoch 31/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4638Epoch 00030: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4637 - val_loss: 1.5498\n",
      "Epoch 32/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4619Epoch 00031: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4618 - val_loss: 1.5516\n",
      "Epoch 33/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4608Epoch 00032: val_loss did not improve\n",
      "382953/382953 [==============================] - 656s - loss: 1.4608 - val_loss: 1.5507\n",
      "Epoch 34/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4588Epoch 00033: val_loss improved from 1.54551 to 1.54462, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 659s - loss: 1.4588 - val_loss: 1.5446\n",
      "Epoch 35/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4577Epoch 00034: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4576 - val_loss: 1.5530\n",
      "Epoch 36/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4556Epoch 00035: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382953/382953 [==============================] - 658s - loss: 1.4555 - val_loss: 1.5497\n",
      "Epoch 37/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4530Epoch 00036: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4530 - val_loss: 1.5464\n",
      "Epoch 38/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4537Epoch 00037: val_loss did not improve\n",
      "382953/382953 [==============================] - 657s - loss: 1.4537 - val_loss: 1.5469\n",
      "Epoch 39/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4534Epoch 00038: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4534 - val_loss: 1.5459\n",
      "Epoch 40/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4532Epoch 00039: val_loss improved from 1.54462 to 1.54242, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 660s - loss: 1.4531 - val_loss: 1.5424\n",
      "Epoch 41/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4503Epoch 00040: val_loss did not improve\n",
      "382953/382953 [==============================] - 661s - loss: 1.4503 - val_loss: 1.5441\n",
      "Epoch 42/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4467Epoch 00041: val_loss did not improve\n",
      "382953/382953 [==============================] - 660s - loss: 1.4466 - val_loss: 1.5466\n",
      "Epoch 43/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4460Epoch 00042: val_loss did not improve\n",
      "382953/382953 [==============================] - 659s - loss: 1.4460 - val_loss: 1.5469\n",
      "Epoch 44/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4472Epoch 00043: val_loss did not improve\n",
      "382953/382953 [==============================] - 668s - loss: 1.4472 - val_loss: 1.5469\n",
      "Epoch 45/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4429Epoch 00044: val_loss did not improve\n",
      "382953/382953 [==============================] - 672s - loss: 1.4430 - val_loss: 1.5503\n",
      "Epoch 46/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4426Epoch 00045: val_loss improved from 1.54242 to 1.54091, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 659s - loss: 1.4426 - val_loss: 1.5409\n",
      "Epoch 47/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4425Epoch 00046: val_loss improved from 1.54091 to 1.54069, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 658s - loss: 1.4425 - val_loss: 1.5407\n",
      "Epoch 48/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4432Epoch 00047: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4432 - val_loss: 1.5408\n",
      "Epoch 49/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4397Epoch 00048: val_loss improved from 1.54069 to 1.54037, saving model to best_RNN_dropout_from_48.hdf5\n",
      "382953/382953 [==============================] - 658s - loss: 1.4397 - val_loss: 1.5404\n",
      "Epoch 50/50\n",
      "382750/382953 [============================>.] - ETA: 0s - loss: 1.4398Epoch 00049: val_loss did not improve\n",
      "382953/382953 [==============================] - 658s - loss: 1.4397 - val_loss: 1.5495\n"
     ]
    }
   ],
   "source": [
    "#model = get_simple_rnn()\n",
    "checkpointer = ModelCheckpoint(filepath='best_RNN_dropout_from_48.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, batch_size=250, epochs=50, verbose = 1, \n",
    "                    validation_data = (X_validation, y_validation),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('history_deep_dropout_from48', (loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa44ab3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Epochs Simple no dropout"
   ]
  },
  {
   "attachments": {
    "history_graph_20_epochs.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX9//HXyR7IvgEJCWHf9yQiKiru1KVVW7VfrdYqUv229VdbbW2rtt+2Vm2tVVupC+5F3Kq4IooKiggBw74vgRAgC5ANss75/XEHCCEbMJlJZt7Px2MeM5l7MvfjdXjPyZlz7zHWWkRExL8E+boAERHxPIW7iIgfUriLiPghhbuIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPihEF/tOCkpyWZmZvpq9yIiXdLSpUtLrLXJbbXzWbhnZmaSm5vrq92LiHRJxpj89rTTsIyIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPghhbuIiB/qcuG+fncFf3pvDQdrG3xdiohIp9Xlwr1g3wGeWrCVvB37fV2KiEin1eXCPatPAgC52/b6uBIRkc6ry4V7bLdQBveIZkn+Pl+XIiLSaXW5cAfIyoxnWf4+GlzW16WIiHRKXTLcc/omUFlTz9pd5b4uRUSkU+qS4Z6VqXF3EZHWdMlwT4uLJDU2giXbNO4uItKcLhnuANl9E1iybS/WatxdRKSpLhvuWZkJFFXUsGPvQV+XIiLS6XTZcM/OjAdgicbdRUSO0WXDfVBKNDERIQp3EZFmdNlwDwoyZGUmKNxFRJrRZcMdnJOZNhdXUVpZ4+tSREQ6lS4d7jmH5rvrUgQiIkdpM9yNMenGmE+NMWuNMauNMT9rpW22MabBGHOlZ8ts3sjesYSFBOlkJhGRJkLa0aYeuMNau8wYEw0sNcbMtdauadzIGBMMPADM6YA6mxUeEszo3rE6mUlEpIk2e+7W2l3W2mXuxxXAWiCtmaY/Ad4AijxaYRuyMhNYtbOMA7X13tytiEindlxj7saYTGAs8HWT59OA7wDT2/j9qcaYXGNMbnFx8fFV2oKczATqXVaLd4iINNLucDfGROH0zG+31ja9HOMjwF3W2lbXvrPWPmmtzbLWZiUnJx9/tc0YlxGPMZCroRkRkcPaM+aOMSYUJ9hftta+2UyTLOAVYwxAEjDFGFNvrX3LY5W24PDiHfpSVUTksDbD3TiJ/Qyw1lr7cHNtrLV9G7V/DnjXG8F+SHZmAm8uK6C+wUVIcJee3Ski4hHtScLTgOuAycaYPPdtijFmmjFmWgfX1y5ZmfFU1TawbneFr0sREekU2uy5W2u/AEx7X9Bae8PJFHQist0nMy3eupcRabHe3r2ISKfjF2MYqXGRpMVFkpuvcXcREfCTcAfnEsBLtu3T4h0iIvhRuGdlJlBcUcP2vQd8XYqIiM/5Tbjn9D0y7i4iEuj8JtwHJEcRGxmqk5lERPCjcA8KMmT1iWeJvlQVEfGfcAfI7pvAluIqSrR4h4gEOP8Kd/ei2RqaEZFA51fhPiJNi3eIiICfhXt4SDBj0uN0ETERCXh+Fe7gDM2sKizX4h0iEtD8LtyzMhNocFnytmvxDhEJXH4X7uP7OIt3LNbQjIgEML8L95iIUIb0jNGMGREJaH4X7uCMuy/bvo/6BpevSxER8Qk/DfcEDtQ2sGZX06VeRUQCg1+Ge5b7ZKYlGpoRkQDll+HeKzaS3vGROplJRAKWX4Y7QE5mAku27dXiHSISkPw23LMyEyiprGVbqRbvEJHA47fhnn143F1DMyISeLpeuLtcsOmTNpsNSIkivluoxt1FJCB1vXD/5kV46XLYPK/VZsYYxvdJ0IwZEQlIXS/cR18N8X3hw19DQ+sXB8vOjGdrSRXFFVq8Q0QCS9cL95BwuOBPULwOcp9ptWlWprNo9lItvSciAabNcDfGpBtjPjXGrDXGrDbG/KyZNv9jjFnhvi00xozumHLdBk+BfmfDp3+CqtIWm41MiyU8JIjFWzU0IyKBpT0993rgDmvtUGACcJsxZliTNluBM621o4D/A570bJlNGAMX3g81lU7AtyAsJIgx6XHkqucuIgGmzXC31u6y1i5zP64A1gJpTdostNYe6h4vAnp7utBjpAyF7Jtg6bOwe1WLzbIzE1hdWE5VjRbvEJHAcVxj7saYTGAs8HUrzX4EfNDC7081xuQaY3KLi4uPZ9fNO/vXEBEHH/4KWjgTNbuvs3jHN1q8Q0QCSLvD3RgTBbwB3G6tbfZyi8aYs3HC/a7mtltrn7TWZllrs5KTk0+k3qNFxsPk38C2BbB2drNNxmXEEWR0MpOIBJZ2hbsxJhQn2F+21r7ZQptRwNPAZdbalr/l9LTxP4QeI2DOb6Hu4DGbow8t3qFxdxEJIO2ZLWOAZ4C11tqHW2iTAbwJXGet3eDZEtsQFAwX/gXKtsPCx5ttktM3gWX5+6nT4h0iEiDa03M/DbgOmGyMyXPfphhjphljprnb3AMkAv9yb8/tqIKb1fcMGHYZfPEwlO08ZnNWZjwH6xpYU6jFO0QkMIS01cBa+wVg2mhzE3CTp4o6Ief9H2yYAx/fC1c8fdSmbPfJTEu27WV0epwvqhMR8aqud4ZqS+L7wMSfwsrXYPuiozb1iIkgI6GbvlQVkYDhP+EOcPrtEJ0KH9zpXD2ykazMeHK37dPiHSISEPwr3MO6w3l/gF3LIe/lozZlZyZQWlXL1pIqHxUnIuI9/hXuACOvhPQJ8Mnvobrs8NOHxt1zdQlgEQkA/hfuxsBFf4GqEpj/0OGn+yd3J75bKIs17i4iAcD/wh0gdSyMvRYWTYeSTYCzeEdWZoJWZhKRgOCf4Q5wzj0QGglz7j78VE5mAttKD1BUUe3DwkREOp7/hntUCpx5J2ycAxvnAs6MGdC4u4j4P/8Nd4CcWyBxgLMkX30tw1NjiQgN0nx3EfF7/h3uIWFwwf1QuhEWP0lYSBBj0+PVcxcRv+ff4Q4w6HwYcB58/gBUFpOdGc/qwjIqqut8XZmISIfx/3AHuODPUHcA5v2BMwen4LLw6CcbfV2ViEiHCYxwTx4Ep0yDZS8yPjSfaydk8NSCrXyxscTXlYmIdIjACHeASb+Ebonw4a/4zUVD6Z/cnTtey2NfVa2vKxMR8bjACffIOGfu+/aviNzwFv+4eix7q2q5+78rdTExEfE7gRPu4Jy12nMUzL2HEfEN3HH+YD5YtZvXcgt8XZmIiEcFVrgHBcO3/uZcd+apyUwdUsep/RK5753VbNPVIkXEjwRWuAOk58AN70FtFUEzzuPxnFJCggw/m5WnNVZFxG8EXrgDpGfDzfMgrg+Jb1/LzFF5LN+xj8c0PVJE/ERghjtAXDrc+CEMnsLwFX9mZs9XmP7pOl2aQET8QuCGO0B4FHzvRTj955y6/x1eiXyIe15ZQLnOXhWRLi6wwx0gKAjOvRe+82/GsJ4nDt7JP19939dViYicFIX7IaOvJuiGd0kJq+G2zdP46qPXfF2RiMgJU7g3lnEKYdM+Y29ICtkLp7L/s8d9XZGIyAlRuDcRkphJ8E1zWWDHEvfZb3C9+3No0Bi8iHQtbYa7MSbdGPOpMWatMWa1MeZnzbQxxphHjTGbjDErjDHjOqZc70jvlULpJc8yvf4SgnKfgZeugIO6BryIdB3t6bnXA3dYa4cCE4DbjDHDmrS5CBjovk0FnvBolT5wxfgMVg77OXfWT8OVvxCePvfwYtsiIp1dm+Furd1lrV3mflwBrAXSmjS7DHjBOhYBccaYXh6v1ouMMfz52yNZ0P18bg//A/bAPnh6Mmz5zNeliYi06bjG3I0xmcBY4Osmm9KAHY1+LuDYDwCMMVONMbnGmNzi4uLjq9QHYruF8rfvjead/X14qM8TEJ0KL14Oi58CXUlSRDqxdoe7MSYKeAO43Vpb3nRzM79yTPpZa5+01mZZa7OSk5OPr1Ifmdg/iamT+vGvvHo+Oe0lGHAuvP8LmHUtVOzxdXkiIs1qV7gbY0Jxgv1la+2bzTQpANIb/dwbKDz58jqHO84bzIi0GH4xewtF33oWzr0PNs6Ff50CK15VL15EOp32zJYxwDPAWmvtwy00mw38wD1rZgJQZq3d5cE6fSosJIhHrhrLwboGfvHmalwTb4dpCyBxALx5M7zyfajY7esyRUQOa0/P/TTgOmCyMSbPfZtijJlmjJnmbvM+sAXYBDwF3Nox5frOgJQofvutYczfUMzzX22D5MFw4xw4/4+weR78MwfyZqoXLyKdgvHVEnNZWVk2NzfXJ/s+UdZabn4hl/kbS3jxxhxO6ZfobCjZBG/fBjsWwcAL4JJHICbVt8WKiF8yxiy11ma11U5nqB4HYwwPXDGKjIRuXP/sYr7YWOJsSBoAP3wfLrgfts6Hf06Ab15SL15EfEbhfpwSo8J5ZeoEMhO7c+PzS/h0fZGzISgYTr0Vfvwl9Bju9ORfvhLKtD6riHifwv0EJEWFM/PmCQzqEcUtLyxl7ppGUyIT+zvL+F30EOQvdHrxS59XL15EvErhfoLiu4fx8k0TGJoaw49fWsr7KxtNDgoKglOmwo8XQuoYeOen8OJ3YP923xUsIgFF4X4SYiNDeelHOYxJj+MnM7/h7bydRzdI6As/mA3f+hvsWAz/OhVyZ6gXLyIdTuF+kqIjQnn+xhyyM+O5fVYer+XuOLpBUBBk3wS3fgVp4+Hd/wcvXAp71vimYBEJCAp3D+geHsKzN+Rw+oAkfvn6Cv7zdTPDL/F94Advw8WPQGEeTD8N3roNynYe21ZE5CQp3D0kMiyYp36QxeQhKdz935U89+XWYxsZA1k/hJ8th1N+DCtfhcfGwdx7dL14EfEohbsHRYQGM/3a8VwwvAf3vbOGJ+dvbr5htwS48M/wv7kw7DL48lH4xxjnvq7au0WLiF9SuHtYWEgQj39/HBeP6sWf31/H4/M2ttw4vg9c/iTcMt8Zj5/7O3g8y7mMgavBe0WLiN9RuHeA0OAgHrlqDJePTeOvH23g4Y/W0+plHnqNguvedMbkuyXCW9Ng+hmw4SPNrBGRE6Jw7yAhwUE89N3RXJWVzqPzNvGXD9e1HvAA/c6Cmz+FK2dAXRX857vw/CVQsNQbJYuIH1G4d6DgIMP9l4/k2gkZ/PvzLfzh3TVtB3xQEIy4Am5bAhc9CEVrnOX9Xr0eSlsYwxcRaSLE1wX4u6Agw/9dNoKw4GBmfLmVugYXf7h0BEFBzS1e1UhIGJxyC4y+BhY+Bl89DuvehfE3wJl3QVSKV+oXka5J4e4Fxhh+d/FQwkKCmP75ZurqLX/6zghCgtvxh1NEDEz+jXMi1OcPQO6zzheuY691wj+xf8f/B4hIl6NhGS8xxnDXhYP52TkDmZW7g+ufXczeqtr2v0B0D7j4YbhtMQy9xLmMwWPj4T9XwZbP9MWriBxFi3X4wKu5O/jtW6tIjgrniWvHMap33PG/SMVuWPKME/IHSiBlGJwyDUZ9D0IjPV+0iHQK7V2sQ+HuIysLypj20lKKK2v442Uj+F52etu/1Jy6alj1Bix6AvashMgE5yzY7Ju0GpSIH1K4dwF7q2r56cxv+GJTCd8/JYN7LxlGeEjwib2YtbDtC/h6Oqx7z1k8ZNi3YcKt0Hu8ZwsXEZ9RuHcRDS7LXz9azxOfbWZMehxPXDuOXrEnOayydyssfgqWvQC1FdA7Gyb8GIZeCsGhnilcRHxC4d7FfLhqF3e8upzIsGAeu2Ycp/ZPPPkXramAvP84Qzb7tkJ0KuTc7Eyn7JZw8q8vIl6ncO+CNhVVMPXFpeSXHuDXFw3hR6f3xZg25sO3h8sFGz+CRf+CrZ9DSIRzwbIx/wOZZzgnTolIl6Bw76Iqquv4xWvLmbN6DxeP6sWDV46iW5gHT0fYsxqWPA0r34CaMojLcEJ+9DXOhcxEpFNTuHdh1lqe+Hwzf52znoEp0Uy/bjx9k7p7did1B2Htu5D3Emz5HLDQ90zn5Kihl2g6pUgnpXD3Aws2FvOTmd/Q4LI8ctUYzhnao2N2tH+7c9Zr3suwPx/CY5zr24y91rkUsSeGhkTEIzwW7saYGcDFQJG1dkQz22OBl4AMnMsZ/NVa+2xbO1a4t8+OvQf48ctLWbWznJ+eM5DbzxnY9nVpTpTLBflfwDcvw5q3of4gJA9xhm1GXeWcJSsiPuXJcJ8EVAIvtBDudwOx1tq7jDHJwHqgp7W21XPrFe7tV13XwG/fWsXrSws4e3Ayj1w1lthuHTylsbocVr/pBH3BYjDBMPB8pzc/6AJNqRTxkfaGe5vf1Flr5xtjMltrAkQbZ1pHFLAXqG9nndIOEaHBPHTlKMakx/H7d1ZzyeNf8PerxjC+T3wH7jTGmTI5/gYo3uCMzS9/BTZ84CwoMvACGHgu9Dtb0ypFOqF2jbm7w/3dFnru0cBsYAgQDVxlrX2vhdeZCkwFyMjIGJ+fn3/ChQeqpfn7+OnMbygsO8iPTuvLHecPJjLsBM9qPV4N9bD5E1gxCzbPcxb1NkGQlgUDznVuqWM1tVKkA3n0C9U2wv1K4DTg50B/YC4w2lpb3tpraljmxFXW1HP/+2t5+evtZCZ248ErR5PT18u9Z1cD7FwGm+bCpo+dx1inV99/Mgw4z7mPSvZuXSJ+zpvh/h7wF2vtAvfP84BfWWsXt/aaCveTt3BTCXe9uYKCfQe5/tRM7rxwsGfnxB+PqhLY/KkT9Js+dq5UCdBrDAw8z+nVp2VBsJYQEDkZ3gz3J4A91tr7jDE9gGU4PfeS1l5T4e4ZVTX1PDRnPc8t3EZGQjceuGKUZy5dcDJcLti9HDa6g75gMVgXRMQ6Y/QDzoWMU52FRjTNUuS4eHK2zEzgLCAJ2APcC4QCWGunG2NSgeeAXoDB6cW/1NaOFe6e9fWWUu58YwX5pQe4dkIGv7poKFHhnaSXfHCfs6DIpo9h0ydQsct5PiLOmUffO8u5uFnaeH05K9IGncQUgA7WNvDXj9Yz48utpMZG8sAVozh9YJKvyzqatVC8DgqWQEGucyte6/TsARL6OcM3vbOdSxX3GOmsJysigMI9oC3N38svX1vBlpIqrslJ5+4pQ4mO6MTz0msqofAb2Jl7JPArdzvbgsOh12ind3+olx/XR8M5ErAU7gGuuq6Bv8/dwFMLttAzJoL7rxjFmYO6yMwVa6F8pzvol8DOpVCY55wxC9A92Qn6tCxIG+fcIjtwzr9IJ6JwFwC+2b6PO19fwcaiSr47vje/vXgYsZGduBffkoY6KFpzpGe/cymUbMA5hw5IHOAOfHfo9xwBIeE+LVmkIyjc5bCa+gYe/WQj0z/fQlJUGPdfPpLJQ/zgOjHVZe7hnKXOPPvGwzlBodBz5JHhnLTxkNBfJ1hJl6dwl2OsLCjjl68vZ93uCi4a0ZPffGsoveO7+bosz7EWygvdYZ/rBH7hN1Bb6WyPiIVU9zBObDpEpUD3FOc+KkWXOZYuQeEuzaqtd/HUgi08Pm8TFsuPzxzALWf2IyLUS5cw8DZXAxSvbxT4S2HPGrANx7YNi3bOqI3q4YzrNw3/7ilHtuuDQHxE4S6tKtx/kD+9v5b3VuwiPSGS331rGOcN6+GZZf06u/paqCqCyiKoKnbuK/cceVxV7PxcWQTV+5t/jagezrTNhP6Q2O/I44R+EB7l3f8eCSgKd2mXhZtLuG/2ajbsqWTSoGTuvWQY/ZMVTofV1x4J+8MfBLth7zbYuwX2bna2NRbV40jQJzYKfQW/eIDCXdqtrsHFi1/l8/e5G6iub+DG0/vyk8kDO88Zrp1dTQXs3eoEfenmox9XFR3dNqqnE/KxvSEmFWLSIKbXkcfdkyHIT4fIxCMU7nLciitqePDDdby2tIAeMeHcPWUol45ODYyhmo5SU+H08Es3u3v67lv5TijfBa66o9sHhUB0L+d2OPxTj/4giO6lxVICmMJdTtiy7fu4b/ZqVhSUkZOZwH2XDmdYaoyvy/I/Lpdz9cxDQV++05ntU14IFYVHHtcdOPZ3TbDTwzdBjW7Bzpm7JqjJtkOPzZHnw6Kc2UMRMe77OGft3IjYJs/HHnk+PKZrTiV1NTgfsjXlzgpjNRXOh6q17steuO8tjX5uus0evQ3cZ0mb1u9NUJPncO7jM50L550AhbucFJfL8mruDh6cs579B2q5dkIffn7eIOK66TovXmWt86VueeGRD4CK3dBQ4w4dlxNeh8LHNhx5vqVtrnqorXLOE6gud9+XQV1VG8UYCI92Qj44tNEHSKMPkqAmHyjHfAC5nwsKda4ZFNz0Furch4QfeRwcfvTzQSFQd9AJ68OB3cx9TYXzuLbCK/+rjstpt8N5vz+hX1W4i0eUHajj4bnreXFRPrGRodx54RC+l5VOcEct0i2+01DnDsT9xwZ/TfnRz7nqGn14uJr5QGn8YdJ4e4Oz3VXn7K+h1vnSuqHJzXUcK3WGRLj/uog58uETEQPh7r9Amm4Lj3Y+KA79NdO4d33U48Y/BzXpmePuwdv23Td9LroXxPc5of9NCnfxqDWF5dw3ezWLt+1lZFosd08Z6vvrxov/crmcD4D6miMfAg2NHodEHBkqCrCrhircxeOstcxeXsj9769jd3k1Zw5K5pcXDGZEWqyvSxMJGO0N9y747Yj4ijGGy8ak8dkvz+LuKUPI27Gfix/7gp/O/IZtJW2N14qIN6nnLies7GAdT87fzIwvtlHX4OLqnHR+es5AUqIjfF2aiN/SsIx4TVF5NY/O28gri3cQGhzEjadncsuZ/YnpzAuEiHRRCnfxum0lVTw8dwOzlxcS1y2UW8/qzw9OzfTfi5KJ+IDCXXxm1c4yHpqzns83FNMrNoLbzx3IFeN6ExKsr3hETpa+UBWfGZEWy/M35jDz5gn0iIngrjdWcsEj8/lw1S581ZkQCTQKd+kwp/ZP5L+3TuTf143HGMO0l5bx7X8tZOGmEl+XJuL3NCwjXtHgsry5rIC/z91AYVk14zLimDqpP+cP60GQznYVaTeNuUunVF3XwKwlO3j6iy3s2HuQfknduemMflw+Lk1fvIq0g8JdOrX6Bhcfrt7Nk/O3sKKgjKSoMK4/NZPrTu2ji5OJtMJj4W6MmQFcDBRZa0e00OYs4BEgFCix1p7Z1o4V7gLOJQ0WbdnLv+dv5rP1xUSGBnNVdjo/Or0v6Ql+tHi3iId4MtwnAZXAC82FuzEmDlgIXGit3W6MSbHWFjVt15TCXZpav7uCJ+dvYfbynbgsTBnZi1sm9dO1a0Qa8eiwjDEmE3i3hXC/FUi11v72eApUuEtLdpdV8+yXW/nP19upqKlnYv9Epk7qx5mDkrUqlAQ8b4b7oeGY4UA08A9r7QstvM5UYCpARkbG+Pz8/Db3LYGrvLqOmV9v59kvt7G7vJohPaO5+Yx+XDI6lbAQzeKVwOTNcH8cyALOASKBr4BvWWs3tPaa6rlLe9XWu5i9vJCn5m9h/Z4KesZEcE1OBt/L7k2v2EhflyfiVe0Nd08sb1+A8yVqFVBljJkPjAZaDXeR9goLCeLK8b25Ylwan20oZsYXW/n7xxv4xycbOGtwCldnpzN5SIoubyDSiCfC/W3gcWNMCBAGnAL83QOvK3IUYwxnD07h7MEpbC89wKzc7byWW8DUdUWkRIfz3azeXJ2doVk2IrRvtsxM4CwgCdgD3Iszxo61drq7zS+BHwIu4Glr7SNt7VjDMuIJ9Q0u5q0r4pUlO/hsfREuC6cPSOKanAzOG9ZDY/Pid3QSkwScwv0HeS23gFdzd7Bz/0ESu4dxxfjeXJWdTv/kKF+XJ+IRCncJWA0uy/yNxbyyeDufrC2i3mXJ6ZvA1dnpTBnZS5c5kC5N4S4CFFVU8/rSAmYt2UF+6QFiIkL4ztg0Lh/Xm1G9YzVvXrochbtIIy6XZdGWUmYu2cGcVbupbXCRkdCNS0b34pLRqQzpGePrEkXaReEu0oKyA3XMWb2bd1YU8uWmElwWBvWI4pJRqVw8OpW+Sd19XaJIixTuIu1QXFHDh6t28c7yXSzetheAkWmxXDK6FxePSiU1TidJSeeicBc5ToX7D/Leil28s6KQFQVlAGRnxnPJ6FQuGtGL5OhwH1coonAXOSnbSqp4d0Uh7yzfxfo9FQQZmNg/iUtHp3LB8J7Edgv1dYkSoBTuIh6yfncF7ywv5J0VheSXHiA02HBK30TOHpLCOUNSyNQYvXiRwl3Ew6y1rNxZxnsrdvHJuiI2FVUC0C+pO2cPSWHykBSyMxN0Vqx0KIW7SAfbXnqAeev2MG99MYs2l1Lb4CIqPITTByQxeWgKZw1OJiU6wtdlip9RuIt40YHaer7cVOqE/boi9pTXADCqdyxnD3Z69SPTYgkK0klTcnIU7iI+Yq1lza5yPl1XxCfrisjbsR9rISkqnLMHJzN5SAqnDUwiJkJfysrxU7iLdBKllTV8vqGYeeuK+HxDMRXV9QQHGcamxzFpUDJnDExiVO84gtWrl3ZQuIt0QnUNLpbl72P+xmIWbCxh5c4yrIXYyFBOH5DEpEFJnDEwWSdPSYsU7iJdQGllDV9sKmHBxhIWbCw+PFY/ICWKSQOTOWNQEhP6JhIZpitZikPhLtLFWGvZsKeS+RuKmb+xmK+37qW23kVYcBDZfeOZNDCZSYOSGdIzWlezDGAKd5Eurrquga+37mWBO+w37HHm1SdHh3Na/0Qm9k/i1P6JWlYwwHhzgWwR6QARocGcOSiZMwclA7C7rPrwWP0Xm0p4K68QgPSESCb2S2LigERO7ZdISozm1ot67iJdkrWWjUWVfLW5lIWbS/hqcynl1fUA9E/uzsT+SUzsn8iEfonEdw/zcbXiSRqWEQkgDS7L2l3lLNxcwsLNpSzeupcDtQ0YA0N7xjCxfyITBySSnZlAtObXd2kKd5EAVtfgYkXBfhZuKmXh5lKWbt9Hbb2L4CDDqN6x5GQmML5PPOP7xJMYpUsZdyUKdxE5rLqugWX5+1i4uZSvtpSysqCM2gYX4Fz4bHyfeLIy4xnfJ4H+yd01G6cT0xeqInJYRGgwEwckMXFAEuCE/cqdZeRu28fS/L18vHYPry0tACC+W6i7V59AVmY8I9Oj8geyAAAKlUlEQVRiiQjVPPuuRuEuEoAiQoPJzkwgOzMB6I+1ls3FVSzN3+sO/H18vLYIgLDgIEb2jiXLPYwT6EM520qq6Bkb0ek/8DQsIyLNKq2sYWm+E/S5+fuOGsrpk9iN0b3jGJMex5iMOIb1iun0YXey9lXV8pcP1jErdwcj02KZcUO2T5Ze9NiYuzFmBnAxUGStHdFKu2xgEXCVtfb1tnascBfpWqrrGli1s4zc/H0s37GfvB372VVWDUBosGForxjGpMc5oZ8RR9/E7n5xiWOXy/L60gLu/2AtFdX1fHtsGu+uKKRHTAQv3JhDn0TvrsTlyXCfBFQCL7QU7saYYGAuUA3MULiLBIY95dXkuYN++Y79rCgoo7LGmW8fExHC6PS4owI/qYsN56zbXc5v/7uK3Px9ZGfG88dvj2Rwz2iWbd/Hjc8tISTI8OwNOYzsHeu1mjw6W8YYkwm820q43w7UAdnudgp3kQDU4LJsLq48HPh52/ezfk8FDS4nZ9LiIhmTEceotFiGp8YyPDWmU55kVVVTzyMfb2DGl9uIiQjh11OGcuW43kf9JbKpqJLrZyxm/4Fapl83njMGJnulNq+FuzEmDfgPMBl4hlbC3RgzFZgKkJGRMT4/P7/NfYtI13awtoFVhWXkbd9PXoET+Dv3Hzy8PS0ukhFpMYxIjWVEmhP4vrqEgrWWOat38/t31rCrrJprctK584IhLX4A7Smv5voZi9lUVMlfvzuab49N6/AavTkV8hHgLmttQ1tzY621TwJPgtNz98C+RaSTiwxrPDPHsa+qltWF5awqLGN1YTmrd5YxZ/Wew9uTo8MZkRrjDvtYRqTFkBYX2aHz77eXHuDe2av4dH0xQ3vF8Pj3xzG+T3yrv9MjJoJZt5zK1BdyuX1WHiWVNdx0Rr8Oq/F4eKLnvhU4dMSTgAPAVGvtW629poZlRKSxiuo61u6qYNXOMlYVlrGmsJyNRZWHh3RiI0MP9/CHpcYwPDWWvkndT3oFq5r6Bp78fAuPf7qJkCDD/ztvEDdMzCQkOKjdr1Fd18DPX83j/ZW7ufmMvvz6oqEd9mWy13ru1tq+jXb6HM6HQKvBLiLSVHREKDl9E8jpe6SHX13XwLrdTuCvLixj1c5ynv1y2+EpmZGhwQzpFc3w1BiG9XKGdAb3jG73tMwvN5Xwu7dXsaW4iikje3LPxcPpGXv8Q0IRocE8ds04kqJW89SCrRRX1PDglaMJC2n/B4SntRnuxpiZwFlAkjGmALgXCAWw1k7v0OpEJKBFhAY7c+nT4w4/V1vvYnNxpTOc4+7hv51XyEuLtgMQHGTon9yd4amxDOsV4wR/agxx3Y6MmxdVVPPHd9cye3khGQndeO6H2Zw1OOWkag0OMvz+0uH0iIngoTnrKa2q5YlrxxMV7ptzRXUSk4h0edZaduw9yJpdzhj+msJyVheWs7u8+nCbtLhIhqXG0Ds+ktdzC6ipdzHtrP7celZ/j5+A9WruDn795kqG9Yrx+MlOunCYiAS80soa1uwqd/fyy1lTWMbWkipOG5DE7y8dTr/kqA7b97x1e7j15WUeP9lJ4S4i0oz6BtdxfVl6MjriZKf2hrvvRvtFRHzAW8EOMC4jntenTSQ8JJirn/yKBRuLvbZvhbuISAcakBLFm7dOJD2hGz98dglvfbPTK/tVuIuIdLBDJzuN7xPP7bPyePbLrR2+T4W7iIgXxEaG8vyNOVw6OpXMpI6/kqQW6xAR8ZKI0GAevWasV/alnruIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPghhbuIiB9SuIuI+CGfXRXSGFMMnOgK2UlAiQfL8bTOXh90/hpV38lRfSenM9fXx1qb3FYjn4X7yTDG5Lbnkpe+0tnrg85fo+o7Oarv5HT2+tpDwzIiIn5I4S4i4oe6arg/6esC2tDZ64POX6PqOzmq7+R09vra1CXH3EVEpHVdtecuIiKt6NThboy50Biz3hizyRjzq2a2hxtjZrm3f22MyfRibenGmE+NMWuNMauNMT9rps1ZxpgyY0ye+3aPt+pz73+bMWale9/HrEZuHI+6j98KY8w4L9Y2uNFxyTPGlBtjbm/SxuvHzxgzwxhTZIxZ1ei5BGPMXGPMRvd9fAu/e727zUZjzPVerO8hY8w69//D/xpj4lr43VbfDx1Y333GmJ2N/j9OaeF3W/333oH1zWpU2zZjTF4Lv9vhx8+jrLWd8gYEA5uBfkAYsBwY1qTNrcB09+OrgVlerK8XMM79OBrY0Ex9ZwHv+vAYbgOSWtk+BfgAMMAE4Gsf/r/ejTN/16fHD5gEjANWNXruQeBX7se/Ah5o5vcSgC3u+3j343gv1Xc+EOJ+/EBz9bXn/dCB9d0H/KId74FW/713VH1Ntv8NuMdXx8+Tt87cc88BNllrt1hra4FXgMuatLkMeN79+HXgHGOM8UZx1tpd1tpl7scVwFogzRv79qDLgBesYxEQZ4zp5YM6zgE2W2tP9KQ2j7HWzgf2Nnm68fvseeDbzfzqBcBca+1ea+0+YC5woTfqs9Z+ZK2td/+4COjt6f22VwvHrz3a8+/9pLVWnzs7vgfM9PR+faEzh3sasKPRzwUcG56H27jf3GVAoleqa8Q9HDQW+LqZzacaY5YbYz4wxgz3amFggY+MMUuNMVOb2d6eY+wNV9PyPyhfHr9Delhrd4HzoQ6kNNOmsxzLG3H+GmtOW++HjvS/7mGjGS0Ma3WG43cGsMdau7GF7b48fsetM4d7cz3wplN72tOmQxljooA3gNutteVNNi/DGWoYDTwGvOXN2oDTrLXjgIuA24wxk5ps7wzHLwy4FHitmc2+Pn7HozMcy98A9cDLLTRp6/3QUZ4A+gNjgF04Qx9N+fz4AdfQeq/dV8fvhHTmcC8A0hv93BsobKmNMSYEiOXE/iQ8IcaYUJxgf9la+2bT7dbacmttpfvx+0CoMSbJW/VZawvd90XAf3H+9G2sPce4o10ELLPW7mm6wdfHr5E9h4ar3PdFzbTx6bF0f4F7MfA/1j1A3FQ73g8dwlq7x1rbYK11AU+1sF9fH78Q4HJgVkttfHX8TlRnDvclwEBjTF937+5qYHaTNrOBQ7MSrgTmtfTG9jT3+NwzwFpr7cMttOl56DsAY0wOzvEu9VJ93Y0x0Yce43zptqpJs9nAD9yzZiYAZYeGH7yoxd6SL49fE43fZ9cDbzfTZg5wvjEm3j3scL77uQ5njLkQuAu41Fp7oIU27Xk/dFR9jb/H+U4L+23Pv/eOdC6wzlpb0NxGXx6/E+brb3Rbu+HM5tiA8y36b9zP/QHnTQwQgfPn/CZgMdDPi7WdjvNn4wogz32bAkwDprnb/C+wGueb/0XARC/W18+93+XuGg4dv8b1GeCf7uO7Esjy8v/fbjhhHdvoOZ8eP5wPml1AHU5v8kc43+N8Amx03ye422YBTzf63Rvd78VNwA+9WN8mnPHqQ+/DQzPIUoH3W3s/eKm+F93vrxU4gd2raX3un4/59+6N+tzPP3fofdeordePnydvOkNVRMQPdeZhGREROUEKdxERP6RwFxHxQwp3ERE/pHAXEfFDCncRET+kcBcR8UMKdxERP/T/AS/itSZ3xeuEAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![history_graph_20_epochs.png](attachment:history_graph_20_epochs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 101\n",
    "X_test, _ = encode_io_pairs(text_validation[:test_size],chars, window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXOLOTL\n",
      "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
      "Iba a verlos al acuario del Jardín des\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 100, 88)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_validation[:test_size])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHASIZE = len(chars)\n",
    "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "def chars_to_one_hot(sentence, chars):\n",
    "    num_chars = len(chars)\n",
    "    size = max(len(sentence),window_size)\n",
    "    X = np.zeros((1, size, num_chars), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        if char not in chars_to_indices:\n",
    "            char = ' '\n",
    "        X[0, t + size - len(sentence), chars_to_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 50\n",
    "X_text_str = text_validation[:test_size]\n",
    "chars_to_one_hot(X_text_str[0:], chars).astype(int).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escribir sobre nosotros, creyendo imaginar un\n",
      "cuento va a escribir todo esto sobre los axolotl.\n",
      "LA NOC\n"
     ]
    }
   ],
   "source": [
    "## Cuento nuevo\n",
    "print(text_validation[11350:11452])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen resultados distintos entrenamientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una sola epoch, modelo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350912/350934 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2390101701531582"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple = get_simple_rnn()\n",
    "model_simple.load_weights('best_RNN_textdata_weights_01_epochs_step_1_epochs_valid.hdf5')\n",
    "model_simple.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Epochs, modelo simple\n",
    "**Overfitting a partir de aca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 317s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6993086159786712"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.load_weights('best_RNN_textdata_weights_20_epochs_step_1_epochs_valid.hdf5')\n",
    "model_simple.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28 epochs, modelos deep sin dropout en LSTM pero si entre LSTMs\n",
    "**Overfitting a partir de aca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 673s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6121161029150335"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_ndo = get_deeper_no_rnn_dropout()\n",
    "model_deep_ndo.load_weights('best_RNN_textdata_weights_28_epochs_step_1_epochs_valid_2layers.hdf5')\n",
    "model_deep_ndo.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 epochs, modelo deep con dropout en LSTM\n",
    "**Podría seguirla entrenando** Ultima posicion que disminuye: 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 681s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5581404215710672"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_50_epochs.hdf5')\n",
    "model_deep_rnn.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 epochs desde el epoch 48 del anterior, modelo deep con dropout en LSTM\n",
    "**Podría seguirla entrenando** Ultima posicion que disminuye: 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 689s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5403717923841169"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_from_48.hdf5')\n",
    "model_deep_rnn.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    print(a)\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 88)\n",
      "1.0\n",
      "[  1.09773895e-16   9.99987841e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.61068178e-36   1.58657088e-27\n",
      "   4.36446444e-28   1.89791612e-38   0.00000000e+00   5.03110990e-40\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   5.25753109e-33\n",
      "   0.00000000e+00   1.21833045e-05   4.51834104e-27   9.19604354e-27\n",
      "   0.00000000e+00   2.07892436e-40   0.00000000e+00   1.15623589e-25\n",
      "   1.73158184e-18   5.81557357e-29   1.54002701e-42   3.50324616e-44\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.00649232e-44   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sum(pvals[:-1]) > 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-f93bb1863ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_from_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mnew_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_to_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mX_text_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_text_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_char\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-ce0da1d84d9c>\u001b[0m in \u001b[0;36msample\u001b[0;34m(a, temperature)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sum(pvals[:-1]) > 1.0"
     ]
    }
   ],
   "source": [
    "#model = get_simple_rnn()\n",
    "#model.load_weights('best_RNN_textdata_weights_01_epochs_step_1_epochs_valid.hdf5')\n",
    "#model.load_weights('best_RNN_textdata_weights_20_epochs_step_1_epochs_valid.hdf5')\n",
    "# best_RNN_textdata_weights_10_epochs_step_1_epochs_valid\n",
    "# best_RNN_textdata_weights_20_epochs_step_1_epochs_valid\n",
    "# best_RNN_textdata_weights_28_epochs_step_1_epochs_valid_2layers\n",
    "\n",
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_50_epochs.hdf5')\n",
    "\n",
    "model = model_deep_rnn\n",
    "N = 2\n",
    "initial_place = 0\n",
    "test_size = 100\n",
    "X_text_str = text_validation[initial_place:initial_place+test_size] #Arranco del principio\n",
    "#X_text_str = text_validation[11352:11452] #Arrancho de un lugar que tenga mayusculas\n",
    "\n",
    "for i in range(N):\n",
    "    X_test = chars_to_one_hot(X_text_str[i:], chars)\n",
    "    probs = model.predict(X_test)\n",
    "    #new_char = indices_to_chars[sample_from_probabilities(probs)]\n",
    "    probs_norm = probs/probs.sum()\n",
    "    print(probs_norm.shape)\n",
    "    print(probs_norm[0].sum())\n",
    "    print(np.argmax(probs[0]), sample_from_probabilities(probs,1), sample(probs_norm[0],0.1))\n",
    "    new_char = indices_to_chars[sample(probs_norm[0],0.01)]\n",
    "    X_text_str = X_text_str + new_char\n",
    "print(X_text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.42021868,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.28162739,  0.        ,\n",
       "        0.        ,  0.29815391,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what/sum(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/egpu/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(what/sum(what),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AXOLOTL\n",
    "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
    "Iba a verlos al acuario del Jardín de alto de los pasajeros. Es esa menos se acosta\n",
    "de su mujer. El conejo entraron a los caracoles, y la mujer\n",
    "desde los comentamientos de su carrera de los deseos\n",
    "de la mano y encontró con el concierto.\n",
    "\n",
    "**Resultados**:\n",
    "- Aprendio enters\n",
    "- Despues de un punto viene una mayuscula\n",
    "- Plural: los caracoles, los deseos, los comentarmientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_from_probabilities(probabilities, topn=None):\n",
    "    print(len(probabilities))\n",
    "    topn = len(probabilities)\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(topn, 1, p=p)[0]\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [0.15, 0.34, 0.36, 0.15, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 327 µs, sys: 122 µs, total: 449 µs\n",
      "Wall time: 347 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/egpu/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sample(a, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 510 µs, sys: 353 µs, total: 863 µs\n",
      "Wall time: 720 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sample_from_probabilities(a, len(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
